{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be54875a",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "When we are trying to predict if something will happen or not, we have entered the realm of **classification**. In this example, we are going to look at only two possible outcome classes from our customer dataset we have been using: \"big spender\" or \"not big spender\". The data is the file `./data/customers_clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb65523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our most-used packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We'll use a DummyClassifier for fun\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Logistic Regression modules\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Need to measure \"goodness\"\n",
    "# Need to measure \"goodness\"\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, average_precision_score\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and print out its shape\n",
    "cust = pd.read_csv('./data/customers_clean.csv')\n",
    "print(cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b989007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See summary statistics\n",
    "cust.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the following columns:\n",
    "# cust_id, join_date, last_purchase_date\n",
    "new_cust = cust.drop(columns=['cust_id','join_date','last_purchase_date'])\n",
    "new_cust.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c416fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies and save in new DataFrame\n",
    "data = pd.get_dummies(new_cust, dtype=int, drop_first=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4e5c9",
   "metadata": {},
   "source": [
    "## Create \"big spender\"\n",
    "\n",
    "We want to convert the $y$ variable, `spend`, into a binary variable where 1 represents a big spender and a 0 otherwise. We can set the cutoff anywhere we want. Looking at the summary statistics from above, let's use \\$5,700 as the cutoff. We can use the function `pd.cut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927673f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it to see how many will be \"big spenders\"\n",
    "pd.cut(data.spend, bins=[0,5700,10000], right=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecd154",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['big_spender'] = pd.cut(data.spend, bins=[0,5700,10000], right=True, labels=[0,1]).astype(int)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaae769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's try something crazy ... let's fit an OLS model to the data\n",
    "# Plot it to see what it looks like\n",
    "#\n",
    "# Plot household_income on x-axis and big_spender on the y-axis, add regression line\n",
    "sns.regplot(x='household_income', y='big_spender', data=data, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fef913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually we saw issues with the OLS fitted line\n",
    "# This is why we use logistic regression\n",
    "# There is a logit() function statsmodels.formula.api\n",
    "logitResults = smf.logit('big_spender ~ household_income', data=data).fit()\n",
    "logitResults.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output at top different than OLS\n",
    "# Coefficients table useful for p-values and for predictions\n",
    "# Let's plot the logistic regression model\n",
    "# Turn OFF the confidence interval, otherwise it take time to run\n",
    "sns.lmplot(x='household_income', y='big_spender', data=data,\n",
    "          logistic=True, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bcd26",
   "metadata": {},
   "source": [
    "## Split Data into Training and Test Sets\n",
    "\n",
    "Need to first define `X` and `y`. Then we can try train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf16895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output variable, y\n",
    "y = data.big_spender\n",
    "\n",
    "# define the X\n",
    "X = data.drop(columns=['spend', 'big_spender', 'age', 'num_children', 'num_vehicles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208df273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the percentage of big spenders in both training and test?\n",
    "print(f'Training percentage of big spenders is {y_train.mean():.2%}')\n",
    "print(f'Testing percentage of big spenders is  {y_test.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1659b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on just the training X variables\n",
    "# Let's start with StandardScaler which will center\n",
    "# each variable at 0 and give each a unit variance (=1)\n",
    "s_scaler = StandardScaler().fit(X_train)\n",
    "s_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and put in DataFrame\n",
    "X_train_ss = pd.DataFrame(s_scaler.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a86619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the DataFrame\n",
    "X_train_ss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b2518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42966d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_test and put in DataFrame\n",
    "X_test_ss = pd.DataFrame(s_scaler.transform(X_test), columns=X_test.columns)\n",
    "X_test_ss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5825a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7deb821f",
   "metadata": {},
   "source": [
    "# DummyClassifier\n",
    "\n",
    "Let's create a `DummyClassifier` where we will predict the most frequently occurring class, **not** a big spender. How good do you expect this model to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DummyClassifier with constant strategy\n",
    "dummy = DummyClassifier(strategy='constant', constant=0)\n",
    "# Fit it to the training set\n",
    "dummy.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332065b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict on the test set\n",
    "dummy.predict(s_scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can 'score' the dummy classifier for test set\n",
    "dummy.score(X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b920c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix display\n",
    "ConfusionMatrixDisplay.from_estimator(dummy, X_test_ss, y_test, cmap='cividis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ROC Curve display\n",
    "RocCurveDisplay.from_estimator(dummy, X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e761d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Precision Recall Display\n",
    "PrecisionRecallDisplay.from_estimator(dummy, X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffe306",
   "metadata": {},
   "source": [
    "# Create a Logistic Model\n",
    "\n",
    "Let's first create a logistic model with no scaling. We will then scale the data later and see if it helps with prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda4cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression model\n",
    "logReg.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa061be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the estimated intercept and coefficients\n",
    "print(logReg.intercept_)\n",
    "print(logReg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make probability predictions for test set\n",
    "logReg.predict_proba(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get the predicted class for test set\n",
    "logReg.predict(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the confusion matrix\n",
    "confusion_matrix(y_test, logReg.predict(X_test_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a plot of confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(logReg, X_test_ss, y_test, cmap='cividis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can \"unravel\" the values in confusion matrix with .ravel()\n",
    "trueNeg, falsePos, falseNeg, truePos = confusion_matrix(y_test, logReg.predict(X_test_ss)).ravel()\n",
    "\n",
    "print(f'trueNeg : {trueNeg:>4}')\n",
    "print(f'falsePos: {falsePos:>4}')\n",
    "print(f'falseNeg: {falseNeg:>4}')\n",
    "print(f'truePos : {truePos:>4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29680cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first look at the overall error rate and accuracy\n",
    "# Overall error rate = total misclassifications / total chances (sample size)\n",
    "print(f'Overall Error Rate: {(falseNeg+falsePos)/len(y_test):>6.2%}')\n",
    "print(f'Overall Accuracy  : {(trueNeg+truePos)/len(y_test):>6.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at error rates\n",
    "# Find the number of big spenders and others\n",
    "bigSpenders = y_test.sum()\n",
    "others = len(y_test) - bigSpenders\n",
    "print(f'# of big spenders: {bigSpenders}')\n",
    "print(f'# of others      : {others}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good are we with others? We misclassified 70 others\n",
    "# Error rate = false positives / total non-defaulters\n",
    "print(f'Error rate for others: {falsePos/others:>6.2%}')\n",
    "# Accuracy for others = true negatives / total non-defaulters\n",
    "print(f'Accuracy for others  : {trueNeg/others:>6.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about big spenders?\n",
    "# Error rate for big spenders = false negatives / total defaulters\n",
    "print(f'Error rate for big spenders: {falseNeg/bigSpenders:>6.2%}')\n",
    "# Accuracy for defaulters = true positives / total defaulters\n",
    "print(f'Accuracy for big spenders  : {truePos/bigSpenders:>6.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2683ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification_report\n",
    "print(classification_report(y_test, logReg.predict(X_test_ss), target_names=['No','Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0405490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ROC Curve display\n",
    "RocCurveDisplay.from_estimator(logReg, X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc02962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Precision Recall display\n",
    "PrecisionRecallDisplay.from_estimator(logReg, X_test_ss, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70eed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
